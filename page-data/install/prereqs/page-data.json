{"componentChunkName":"component---src-pages-install-prereqs-mdx","path":"/install/prereqs/","result":{"pageContext":{"frontmatter":{"title":"Prerequisites","description":"Prerequisites to validate prior to installation"},"relativePagePath":"/install/prereqs.mdx","titleType":"page","MdxNode":{"id":"7548c36f-c0e0-5fb9-8249-eff9a1185865","children":[],"parent":"914c80aa-a972-5e1d-b072-5a4589fb9309","internal":{"content":"---\ntitle: Prerequisites\ndescription: Prerequisites to validate prior to installation\n---\n\n<PageDescription>\n\nEnsure your environment meets the following requirements prior to installing the DataPower Operator and deploying Custom Resources.\n\n</PageDescription>\n\n<AnchorLinks>\n  <AnchorLink>Container environment</AnchorLink>\n  <AnchorLink>Resource requirements</AnchorLink>\n  <AnchorLink>Cluster-scope permissions</AnchorLink>\n  <AnchorLink>Optional: PodSecurityPolicy</AnchorLink>\n  <AnchorLink>Optional: SecurityContextConstraints</AnchorLink>\n  <AnchorLink>Optional: Multiple Failure Zones</AnchorLink>\n</AnchorLinks>\n\n## Container environment\n\n### Supported platforms\n\nThe DataPower Operator currently supports:\n\n- OpenShift Container Platform (OCP) 4.6+\n- Kubernetes 1.17+\n\n### Worker node configuration\n\nInstallation of the DataPower Operator does not support adding Tolerations to the Operator Deployment resource out-of-the-box. To install properly, there must be one worker in the desired availability zone that is not tainted. If Tolerations are nonnegotiable, you can install the DataPower Operator using the [helm chart](https://github.com/IBM/datapower-operator-chart) and add the Tolerations to the Deployment template manually.\n\n## Resource requirements\n\n### Operator\n\nThe DataPower Operator's `Deployment` uses the following resource spec:\n\n```yaml\nresources:\n  requests:\n    cpu: \"500m\"\n    memory: \"512Mi\"\n  limits:\n    cpu: 2\n    memory: \"2Gi\"\n```\n\nFor more information on what this spec means, see [Managing Resources for Containers](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/).\n\n### Operand\n\n- The **minimum** resource requirements for a single DataPower container are 4 CPU and 4 GB of memory.\n- For API Connect workloads, a minimum of 8 GB of memory is required per container.\n- For production high-availability, a minimum of 3 replicas (one per node) are recommended.\n\nSee also: [System requirements for IBM DataPower Gateways](https://www.ibm.com/support/pages/node/613133)\n\n## Cluster-scope permissions\n\nThe DataPower Operator requires the following cluster-scope permissions. These are brought in by a `ClusterRole` and bound to the operator's `ServiceAccount` via `ClusterRoleBinding`.\n\nPermissions to manage CustomResourceDefinition defaulting and validating webhooks:\n  - API Groups: `admissionregistration.k8s.io`\n  - Resources: `mutatingwebhookconfigurations`, `validatingwebhookconfigurations`\n  - Verbs: `create`, `delete`, `get`, `list`, `patch`, `update`, `watch`\n\nPermissions needed for reconciliation of admission controllers (webhooks):\n  - API Groups: `rbac.authorization.k8s.io`\n  - Resources: `clusterroles`, `clusterrolebindings`\n  - Verbs: `get`, `list`\n\nPermissions needed for management of owned CustomResourceDefinitions:\n  - API Groups: `apiextensions.k8s.io`\n  - Resources: `customresourcedefinitions`\n  - Verbs: `get`, `update`\n\nPermissions needed for management of conversion webhook, which can exist in other namespaces:\n  - API Groups: (none)\n  - Resources: `namespaces`\n  - Verbs: `get`, `list`\n\nPermissions needed for management of conversion webhook, which can exist in other namespaces:\n  - API Groups: (none)\n  - Resources: `services`, `secrets`\n  - Verbs: `create`, `delete`, `get`, `list`, `patch`, `update`, `watch`\n\nPermissions needed for management of conversion webhook, which can exist in other namespaces:\n  - API Groups: `apps`\n  - Resources: `deployments`\n  - Verbs: `create`, `delete`, `get`, `list`, `patch`, `update`, `watch`\n\nPermissions needed for conversion webhook implementation across namespaces:\n  - API Groups: `datapower.ibm.com`\n  - Resources: `*`\n  - Verbs: `create`, `delete`, `get`, `list`, `patch`, `update`, `watch`\n\nPermissions needed for OCP platform related checks:\n  - API Groups: `config.openshift.io`\n  - Resources: `clusterversions`\n  - Verbs: `get`\n\n## Optional: PodSecurityPolicy\n\nThe DataPower Operator is expected to work as-is with the standard `restricted` PodSecurityPolicy; however, if you wish to leverage a more restrictive policy the following can be used.\n\n```yaml\napiVersion: policy/v1beta1\nkind: PodSecurityPolicy\nmetadata:\n  name: ibm-datapower-operator-restricted-psp\nspec:\n  allowPrivilegeEscalation: false\n  forbiddenSysctls:\n    - '*'\n  hostNetwork: false\n  hostPorts: false\n  requiredDropCapabilities:\n    - ALL\n  runAsUser:\n    rule: MustRunAsNonRoot\n  seLinux:\n    rule: RunAsAny\n  volumes:\n    - configMap\n    - emptyDir\n    - projected\n    - secret\n    - downwardAPI\n    - persistentVolumeClaim\n```\n\n## Optional: SecurityContextConstraints\n\nThe DataPower Operator is expected to work as-is with the standard `restricted` SecurityContextConstraints; however, if you wish to leverage a more restrictive constraints the following can be used.\n\n<InlineNotification>\n\n**Note:** This is only applicable to OpenShift (OCP) clusters.\n\n</InlineNotification>\n\n```yaml\nkind: SecurityContextConstraints\napiVersion: v1\nmetadata:\n  name: ibm-datapower-operator-scc\nallowHostDirVolumePlugin: false\nallowHostIPC: false\nallowHostNetwork: false\nallowHostPID: false\nallowHostPorts: false\nallowPrivilegeEscalation: false\nallowPrivilegedContainer: false\nallowedCapabilities: null\napiVersion: security.openshift.io/v1\ndefaultAddCapabilities: null\ngroups:\n  - system:authenticated\npriority: null\nreadOnlyRootFilesystem: false\nrequiredDropCapabilities:\n  - ALL\nrunAsUser:\n  type: MustRunAsNonRoot\nseLinuxContext:\n  type: RunAsAny\nusers: []\nvolumes:\n  - configMap\n  - downwardAPI\n  - emptyDir\n  - persistentVolumeClaim\n  - projected\n  - secret\n```\n\n## Optional: Multiple Failure Zones\n\nThe DataPower Operator `Deployment` is designed to pods evenly across multiple Kubernetes zones. To take advantage of this functionality, follow the [prerequisites](https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#prerequisites) for Pod Topology Spread Constraints.\n\nWith `EvenPodsSpread` enabled in the cluster, no more than one DataPower Operator pod will be deployed per zone. If `replicaCount` is higher than the number of available zones, the remaining replicas will not be scheduled.\n","type":"Mdx","contentDigest":"6d789410f0c21687cbd2d9798f2b7547","counter":116,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Prerequisites","description":"Prerequisites to validate prior to installation"},"exports":{},"rawBody":"---\ntitle: Prerequisites\ndescription: Prerequisites to validate prior to installation\n---\n\n<PageDescription>\n\nEnsure your environment meets the following requirements prior to installing the DataPower Operator and deploying Custom Resources.\n\n</PageDescription>\n\n<AnchorLinks>\n  <AnchorLink>Container environment</AnchorLink>\n  <AnchorLink>Resource requirements</AnchorLink>\n  <AnchorLink>Cluster-scope permissions</AnchorLink>\n  <AnchorLink>Optional: PodSecurityPolicy</AnchorLink>\n  <AnchorLink>Optional: SecurityContextConstraints</AnchorLink>\n  <AnchorLink>Optional: Multiple Failure Zones</AnchorLink>\n</AnchorLinks>\n\n## Container environment\n\n### Supported platforms\n\nThe DataPower Operator currently supports:\n\n- OpenShift Container Platform (OCP) 4.6+\n- Kubernetes 1.17+\n\n### Worker node configuration\n\nInstallation of the DataPower Operator does not support adding Tolerations to the Operator Deployment resource out-of-the-box. To install properly, there must be one worker in the desired availability zone that is not tainted. If Tolerations are nonnegotiable, you can install the DataPower Operator using the [helm chart](https://github.com/IBM/datapower-operator-chart) and add the Tolerations to the Deployment template manually.\n\n## Resource requirements\n\n### Operator\n\nThe DataPower Operator's `Deployment` uses the following resource spec:\n\n```yaml\nresources:\n  requests:\n    cpu: \"500m\"\n    memory: \"512Mi\"\n  limits:\n    cpu: 2\n    memory: \"2Gi\"\n```\n\nFor more information on what this spec means, see [Managing Resources for Containers](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/).\n\n### Operand\n\n- The **minimum** resource requirements for a single DataPower container are 4 CPU and 4 GB of memory.\n- For API Connect workloads, a minimum of 8 GB of memory is required per container.\n- For production high-availability, a minimum of 3 replicas (one per node) are recommended.\n\nSee also: [System requirements for IBM DataPower Gateways](https://www.ibm.com/support/pages/node/613133)\n\n## Cluster-scope permissions\n\nThe DataPower Operator requires the following cluster-scope permissions. These are brought in by a `ClusterRole` and bound to the operator's `ServiceAccount` via `ClusterRoleBinding`.\n\nPermissions to manage CustomResourceDefinition defaulting and validating webhooks:\n  - API Groups: `admissionregistration.k8s.io`\n  - Resources: `mutatingwebhookconfigurations`, `validatingwebhookconfigurations`\n  - Verbs: `create`, `delete`, `get`, `list`, `patch`, `update`, `watch`\n\nPermissions needed for reconciliation of admission controllers (webhooks):\n  - API Groups: `rbac.authorization.k8s.io`\n  - Resources: `clusterroles`, `clusterrolebindings`\n  - Verbs: `get`, `list`\n\nPermissions needed for management of owned CustomResourceDefinitions:\n  - API Groups: `apiextensions.k8s.io`\n  - Resources: `customresourcedefinitions`\n  - Verbs: `get`, `update`\n\nPermissions needed for management of conversion webhook, which can exist in other namespaces:\n  - API Groups: (none)\n  - Resources: `namespaces`\n  - Verbs: `get`, `list`\n\nPermissions needed for management of conversion webhook, which can exist in other namespaces:\n  - API Groups: (none)\n  - Resources: `services`, `secrets`\n  - Verbs: `create`, `delete`, `get`, `list`, `patch`, `update`, `watch`\n\nPermissions needed for management of conversion webhook, which can exist in other namespaces:\n  - API Groups: `apps`\n  - Resources: `deployments`\n  - Verbs: `create`, `delete`, `get`, `list`, `patch`, `update`, `watch`\n\nPermissions needed for conversion webhook implementation across namespaces:\n  - API Groups: `datapower.ibm.com`\n  - Resources: `*`\n  - Verbs: `create`, `delete`, `get`, `list`, `patch`, `update`, `watch`\n\nPermissions needed for OCP platform related checks:\n  - API Groups: `config.openshift.io`\n  - Resources: `clusterversions`\n  - Verbs: `get`\n\n## Optional: PodSecurityPolicy\n\nThe DataPower Operator is expected to work as-is with the standard `restricted` PodSecurityPolicy; however, if you wish to leverage a more restrictive policy the following can be used.\n\n```yaml\napiVersion: policy/v1beta1\nkind: PodSecurityPolicy\nmetadata:\n  name: ibm-datapower-operator-restricted-psp\nspec:\n  allowPrivilegeEscalation: false\n  forbiddenSysctls:\n    - '*'\n  hostNetwork: false\n  hostPorts: false\n  requiredDropCapabilities:\n    - ALL\n  runAsUser:\n    rule: MustRunAsNonRoot\n  seLinux:\n    rule: RunAsAny\n  volumes:\n    - configMap\n    - emptyDir\n    - projected\n    - secret\n    - downwardAPI\n    - persistentVolumeClaim\n```\n\n## Optional: SecurityContextConstraints\n\nThe DataPower Operator is expected to work as-is with the standard `restricted` SecurityContextConstraints; however, if you wish to leverage a more restrictive constraints the following can be used.\n\n<InlineNotification>\n\n**Note:** This is only applicable to OpenShift (OCP) clusters.\n\n</InlineNotification>\n\n```yaml\nkind: SecurityContextConstraints\napiVersion: v1\nmetadata:\n  name: ibm-datapower-operator-scc\nallowHostDirVolumePlugin: false\nallowHostIPC: false\nallowHostNetwork: false\nallowHostPID: false\nallowHostPorts: false\nallowPrivilegeEscalation: false\nallowPrivilegedContainer: false\nallowedCapabilities: null\napiVersion: security.openshift.io/v1\ndefaultAddCapabilities: null\ngroups:\n  - system:authenticated\npriority: null\nreadOnlyRootFilesystem: false\nrequiredDropCapabilities:\n  - ALL\nrunAsUser:\n  type: MustRunAsNonRoot\nseLinuxContext:\n  type: RunAsAny\nusers: []\nvolumes:\n  - configMap\n  - downwardAPI\n  - emptyDir\n  - persistentVolumeClaim\n  - projected\n  - secret\n```\n\n## Optional: Multiple Failure Zones\n\nThe DataPower Operator `Deployment` is designed to pods evenly across multiple Kubernetes zones. To take advantage of this functionality, follow the [prerequisites](https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#prerequisites) for Pod Topology Spread Constraints.\n\nWith `EvenPodsSpread` enabled in the cluster, no more than one DataPower Operator pod will be deployed per zone. If `replicaCount` is higher than the number of available zones, the remaining replicas will not be scheduled.\n","fileAbsolutePath":"/home/travis/build/IBM/datapower-operator-doc/src/pages/install/prereqs.mdx"}}}}